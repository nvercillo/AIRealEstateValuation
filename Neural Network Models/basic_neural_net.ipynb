{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[651170.3]]\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading additional data stored in json column into dataframe\n",
    "\n",
    "# file_name = \"all_housing_data.csv\"\n",
    "\n",
    "\n",
    "\n",
    "# df = pd.read_csv(file_name)\n",
    "\n",
    "# ad = pd.DataFrame()\n",
    "\n",
    "\n",
    "# for i, j in df.iterrows():\n",
    "    \n",
    "    \n",
    "#     if i == 0:\n",
    "#         a_json = json.loads(j['Additional_fields'])\n",
    "        \n",
    "#         data = ast.literal_eval(a_json)\n",
    "#         a = list(data.items())\n",
    "        \n",
    "#         additional_df = pd.DataFrame(a)\n",
    "#         additional_df = additional_df.T\n",
    "        \n",
    "#     else:\n",
    "\n",
    "#         a_json = json.loads(j['Additional_fields'])\n",
    "#         data = ast.literal_eval(a_json)\n",
    "#         a = list(data.values())\n",
    "#         new_row = pd.DataFrame(a).T\n",
    "#         additional_df = additional_df.append(new_row)\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "# new_header = additional_df.iloc[0] \n",
    "# additional_df = additional_df[1:] \n",
    "# additional_df.columns = new_header \n",
    "\n",
    "\n",
    "# additional_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(additional_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sold_price</th>\n",
       "      <th>Squarefootage</th>\n",
       "      <th>Type</th>\n",
       "      <th>Style</th>\n",
       "      <th>Community</th>\n",
       "      <th>Municipality District</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Dens</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Kitchens</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Parking Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>205000</td>\n",
       "      <td>950.0</td>\n",
       "      <td>Condo Apartment</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Black Creek</td>\n",
       "      <td>W05</td>\n",
       "      <td>-79.519841</td>\n",
       "      <td>43.769643</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230000</td>\n",
       "      <td>550.0</td>\n",
       "      <td>Co-op / Co-Ownership Apartment</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>West Hill</td>\n",
       "      <td>E10</td>\n",
       "      <td>-79.182497</td>\n",
       "      <td>43.775476</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>299000</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>Condo Townhouse</td>\n",
       "      <td>Stacked Townhouse</td>\n",
       "      <td>Glenfield-Jane Heights</td>\n",
       "      <td>W05</td>\n",
       "      <td>-79.515943</td>\n",
       "      <td>43.749223</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>275000</td>\n",
       "      <td>250.0</td>\n",
       "      <td>Condo Apartment</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Downsview-Roding-CFB</td>\n",
       "      <td>W05</td>\n",
       "      <td>-79.481416</td>\n",
       "      <td>43.725043</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>305888</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>Condo Apartment</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Glenfield-Jane Heights</td>\n",
       "      <td>W05</td>\n",
       "      <td>-79.515943</td>\n",
       "      <td>43.749223</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6212</th>\n",
       "      <td>6198000</td>\n",
       "      <td>4250.5</td>\n",
       "      <td>Detached</td>\n",
       "      <td>2-Storey</td>\n",
       "      <td>Forest Hill South</td>\n",
       "      <td>C03</td>\n",
       "      <td>-79.418061</td>\n",
       "      <td>43.696341</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6213</th>\n",
       "      <td>7000000</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>Detached</td>\n",
       "      <td>2-Storey</td>\n",
       "      <td>Forest Hill South</td>\n",
       "      <td>C03</td>\n",
       "      <td>-79.417288</td>\n",
       "      <td>43.691219</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6214</th>\n",
       "      <td>7150000</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>Detached</td>\n",
       "      <td>2-Storey</td>\n",
       "      <td>Bridle Path-Sunnybrook-York Mills</td>\n",
       "      <td>C12</td>\n",
       "      <td>-79.390151</td>\n",
       "      <td>43.743789</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6215</th>\n",
       "      <td>6800000</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>Detached</td>\n",
       "      <td>2-Storey</td>\n",
       "      <td>Forest Hill South</td>\n",
       "      <td>C03</td>\n",
       "      <td>-79.415512</td>\n",
       "      <td>43.700019</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6216</th>\n",
       "      <td>10200000</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>Detached</td>\n",
       "      <td>2-Storey</td>\n",
       "      <td>Bridle Path-Sunnybrook-York Mills</td>\n",
       "      <td>C12</td>\n",
       "      <td>-79.388489</td>\n",
       "      <td>43.753694</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6217 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sold_price  Squarefootage                            Type  \\\n",
       "0         205000          950.0                 Condo Apartment   \n",
       "1         230000          550.0  Co-op / Co-Ownership Apartment   \n",
       "2         299000         1100.0                 Condo Townhouse   \n",
       "3         275000          250.0                 Condo Apartment   \n",
       "4         305888         1100.0                 Condo Apartment   \n",
       "...          ...            ...                             ...   \n",
       "6212     6198000         4250.5                        Detached   \n",
       "6213     7000000         5000.0                        Detached   \n",
       "6214     7150000         5000.0                        Detached   \n",
       "6215     6800000         5000.0                        Detached   \n",
       "6216    10200000         5000.0                        Detached   \n",
       "\n",
       "                  Style                          Community  \\\n",
       "0             Apartment                        Black Creek   \n",
       "1             Apartment                          West Hill   \n",
       "2     Stacked Townhouse             Glenfield-Jane Heights   \n",
       "3             Apartment               Downsview-Roding-CFB   \n",
       "4             Apartment             Glenfield-Jane Heights   \n",
       "...                 ...                                ...   \n",
       "6212           2-Storey                  Forest Hill South   \n",
       "6213           2-Storey                  Forest Hill South   \n",
       "6214           2-Storey  Bridle Path-Sunnybrook-York Mills   \n",
       "6215           2-Storey                  Forest Hill South   \n",
       "6216           2-Storey  Bridle Path-Sunnybrook-York Mills   \n",
       "\n",
       "     Municipality District  longitude   latitude  Bedrooms  Dens  Bathrooms  \\\n",
       "0                      W05 -79.519841  43.769643         2     0          1   \n",
       "1                      E10 -79.182497  43.775476         1     0          1   \n",
       "2                      W05 -79.515943  43.749223         3     0          2   \n",
       "3                      W05 -79.481416  43.725043         0     0          1   \n",
       "4                      W05 -79.515943  43.749223         3     0          2   \n",
       "...                    ...        ...        ...       ...   ...        ...   \n",
       "6212                   C03 -79.418061  43.696341         3     2          5   \n",
       "6213                   C03 -79.417288  43.691219         4     2          8   \n",
       "6214                   C12 -79.390151  43.743789         4     1          8   \n",
       "6215                   C03 -79.415512  43.700019         4     1          7   \n",
       "6216                   C12 -79.388489  43.753694         6     3         11   \n",
       "\n",
       "      Kitchens  Rooms  Parking Total  \n",
       "0            1      5            1.0  \n",
       "1            1      4            0.0  \n",
       "2            1      6            1.0  \n",
       "3            1      3            1.0  \n",
       "4            1      6            1.0  \n",
       "...        ...    ...            ...  \n",
       "6212         1     11            3.0  \n",
       "6213         1      9            6.0  \n",
       "6214         1     10            7.0  \n",
       "6215         1      9            6.0  \n",
       "6216         1     11           15.0  \n",
       "\n",
       "[6217 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"dataset_final.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a callback function for early stopping of model\n",
    "def get_callbacks():\n",
    "  return [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_mean_absolute_error', patience=50, verbose=1),\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating custom R^2 performance metric for keras models\n",
    "def r2(y_true,y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res = K.sum(K.square(y_true-y_pred))\n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "X = data.drop(['Sold_price','longitude','latitude','Community','Municipality District'],axis=1)\n",
    "Y = data.drop(['Squarefootage','Type','Style','Community','Municipality District','Bedrooms','Dens','Bathrooms','Kitchens','Rooms','Parking Total','longitude','latitude'],axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sold_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>299000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>305888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6212</th>\n",
       "      <td>6198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6213</th>\n",
       "      <td>7000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6214</th>\n",
       "      <td>7150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6215</th>\n",
       "      <td>6800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6216</th>\n",
       "      <td>10200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6217 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sold_price\n",
       "0         205000\n",
       "1         230000\n",
       "2         299000\n",
       "3         275000\n",
       "4         305888\n",
       "...          ...\n",
       "6212     6198000\n",
       "6213     7000000\n",
       "6214     7150000\n",
       "6215     6800000\n",
       "6216    10200000\n",
       "\n",
       "[6217 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Squarefootage</th>\n",
       "      <th>Type</th>\n",
       "      <th>Style</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Dens</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Kitchens</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Parking Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>950.0</td>\n",
       "      <td>Condo Apartment</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>550.0</td>\n",
       "      <td>Co-op / Co-Ownership Apartment</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>Condo Townhouse</td>\n",
       "      <td>Stacked Townhouse</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250.0</td>\n",
       "      <td>Condo Apartment</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>Condo Apartment</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6212</th>\n",
       "      <td>4250.5</td>\n",
       "      <td>Detached</td>\n",
       "      <td>2-Storey</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6213</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>Detached</td>\n",
       "      <td>2-Storey</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6214</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>Detached</td>\n",
       "      <td>2-Storey</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6215</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>Detached</td>\n",
       "      <td>2-Storey</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6216</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>Detached</td>\n",
       "      <td>2-Storey</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6217 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Squarefootage                            Type              Style  \\\n",
       "0             950.0                 Condo Apartment          Apartment   \n",
       "1             550.0  Co-op / Co-Ownership Apartment          Apartment   \n",
       "2            1100.0                 Condo Townhouse  Stacked Townhouse   \n",
       "3             250.0                 Condo Apartment          Apartment   \n",
       "4            1100.0                 Condo Apartment          Apartment   \n",
       "...             ...                             ...                ...   \n",
       "6212         4250.5                        Detached           2-Storey   \n",
       "6213         5000.0                        Detached           2-Storey   \n",
       "6214         5000.0                        Detached           2-Storey   \n",
       "6215         5000.0                        Detached           2-Storey   \n",
       "6216         5000.0                        Detached           2-Storey   \n",
       "\n",
       "      Bedrooms  Dens  Bathrooms  Kitchens  Rooms  Parking Total  \n",
       "0            2     0          1         1      5            1.0  \n",
       "1            1     0          1         1      4            0.0  \n",
       "2            3     0          2         1      6            1.0  \n",
       "3            0     0          1         1      3            1.0  \n",
       "4            3     0          2         1      6            1.0  \n",
       "...        ...   ...        ...       ...    ...            ...  \n",
       "6212         3     2          5         1     11            3.0  \n",
       "6213         4     2          8         1      9            6.0  \n",
       "6214         4     1          8         1     10            7.0  \n",
       "6215         4     1          7         1      9            6.0  \n",
       "6216         6     3         11         1     11           15.0  \n",
       "\n",
       "[6217 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "\n",
      "['Co-op / Co-Ownership Apartment' 'Condo Apartment' 'Condo Townhouse'\n",
      " 'Det Condo' 'Detached' 'Multiplex' 'Other' 'Semi-Detached'\n",
      " 'Store W/Apt/Offc' 'Townhouse']\n",
      "0       1\n",
      "1       0\n",
      "2       2\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "6212    4\n",
      "6213    4\n",
      "6214    4\n",
      "6215    4\n",
      "6216    4\n",
      "Name: Type, Length: 6217, dtype: int64\n",
      "['1 1/2 Storey' '2 1/2 Storey' '2-Storey' '3-Storey' 'Apartment'\n",
      " 'Bachelor/Studio' 'Backsplit' 'Bungalow' 'Loft' 'Sidesplit'\n",
      " 'Stacked Townhouse']\n",
      "0        4\n",
      "1        4\n",
      "2       10\n",
      "3        4\n",
      "4        4\n",
      "        ..\n",
      "6212     2\n",
      "6213     2\n",
      "6214     2\n",
      "6215     2\n",
      "6216     2\n",
      "Name: Style, Length: 6217, dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'Type': {'Co-op / Co-Ownership Apartment': 0, 'Condo Apartment': 1, 'Condo Townhouse': 2, 'Det Condo': 3, 'Detached': 4, 'Multiplex': 5, 'Other': 6, 'Semi-Detached': 7, 'Store W/Apt/Offc': 8, 'Townhouse': 9}, 'Style': {'1 1/2 Storey': 0, '2 1/2 Storey': 1, '2-Storey': 2, '3-Storey': 3, 'Apartment': 4, 'Bachelor/Studio': 5, 'Backsplit': 6, 'Bungalow': 7, 'Loft': 8, 'Sidesplit': 9, 'Stacked Townhouse': 10}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "d = {}\n",
    "print(len(X.columns))\n",
    "\n",
    "for i in range(len(X.columns)):\n",
    "    #if column is categorical\n",
    "    if type(X.iloc[0,i])==str:\n",
    "#         print(\"categorical\")\n",
    "#         print(X.iloc[0,i])\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        X[X.columns[i]] = le.fit_transform(X[X.columns[i]])\n",
    "        \n",
    "        print(le.classes_)\n",
    "        \n",
    "        print(X[X.columns[i]])\n",
    "        series = X[X.columns[i]]\n",
    "        \n",
    "        d[series.name] = {}\n",
    "        \n",
    "        le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "        \n",
    "        d[series.name] = le_name_mapping\n",
    "        \n",
    "        \n",
    "    \n",
    "    else:\n",
    "        print()\n",
    "#         p = X[X.columns[i]]\n",
    "        \n",
    "#         print(p)\n",
    "#         if p.min()==p.max():\n",
    "#             continue\n",
    "#         p -= p.min()\n",
    "#         p /= p.max()\n",
    "#         X[X.columns[i]] = p\n",
    "\n",
    "\n",
    "print(d)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "yScaler = StandardScaler()\n",
    "yScaler.fit(Y)\n",
    "Y = yScaler.transform(Y)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr,Xts,Ytr,Yts = train_test_split(X,Y,test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-06 18:41:18.877065: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-09-06 18:41:18.877377: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=[X.shape[1]]),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.mean_squared_error,\n",
    "              metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-06 18:41:22.594284: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "195/195 [==============================] - 0s 529us/step - loss: 10422.0059 - mean_squared_error: 10422.0059\n",
      "Epoch 2/500\n",
      "195/195 [==============================] - 0s 482us/step - loss: 1263.7076 - mean_squared_error: 1263.7076\n",
      "Epoch 3/500\n",
      "195/195 [==============================] - 0s 487us/step - loss: 265.2017 - mean_squared_error: 265.2017\n",
      "Epoch 4/500\n",
      "195/195 [==============================] - 0s 486us/step - loss: 45.6552 - mean_squared_error: 45.6552\n",
      "Epoch 5/500\n",
      "195/195 [==============================] - 0s 484us/step - loss: 13.9505 - mean_squared_error: 13.9505\n",
      "Epoch 6/500\n",
      "195/195 [==============================] - 0s 485us/step - loss: 5.0732 - mean_squared_error: 5.0732\n",
      "Epoch 7/500\n",
      "195/195 [==============================] - 0s 465us/step - loss: 2.0148 - mean_squared_error: 2.0148\n",
      "Epoch 8/500\n",
      "195/195 [==============================] - 0s 498us/step - loss: 1.6451 - mean_squared_error: 1.6451\n",
      "Epoch 9/500\n",
      "195/195 [==============================] - 0s 480us/step - loss: 0.8816 - mean_squared_error: 0.8816\n",
      "Epoch 10/500\n",
      "195/195 [==============================] - 0s 467us/step - loss: 0.7159 - mean_squared_error: 0.7159\n",
      "Epoch 11/500\n",
      "195/195 [==============================] - 0s 471us/step - loss: 0.6751 - mean_squared_error: 0.6751\n",
      "Epoch 12/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.7476 - mean_squared_error: 0.7476\n",
      "Epoch 13/500\n",
      "195/195 [==============================] - 0s 467us/step - loss: 0.5561 - mean_squared_error: 0.5561\n",
      "Epoch 14/500\n",
      "195/195 [==============================] - 0s 463us/step - loss: 0.5704 - mean_squared_error: 0.5704\n",
      "Epoch 15/500\n",
      "195/195 [==============================] - 0s 466us/step - loss: 0.5669 - mean_squared_error: 0.5669\n",
      "Epoch 16/500\n",
      "195/195 [==============================] - 0s 467us/step - loss: 0.4939 - mean_squared_error: 0.4939\n",
      "Epoch 17/500\n",
      "195/195 [==============================] - 0s 462us/step - loss: 1.2613 - mean_squared_error: 1.2613\n",
      "Epoch 18/500\n",
      "195/195 [==============================] - 0s 466us/step - loss: 0.5673 - mean_squared_error: 0.5673\n",
      "Epoch 19/500\n",
      "195/195 [==============================] - 0s 462us/step - loss: 0.6691 - mean_squared_error: 0.6691\n",
      "Epoch 20/500\n",
      "195/195 [==============================] - 0s 469us/step - loss: 1.1275 - mean_squared_error: 1.1275\n",
      "Epoch 21/500\n",
      "195/195 [==============================] - 0s 462us/step - loss: 0.8571 - mean_squared_error: 0.8571\n",
      "Epoch 22/500\n",
      "195/195 [==============================] - 0s 469us/step - loss: 2.2384 - mean_squared_error: 2.2384\n",
      "Epoch 23/500\n",
      "195/195 [==============================] - 0s 468us/step - loss: 1.2864 - mean_squared_error: 1.2864\n",
      "Epoch 24/500\n",
      "195/195 [==============================] - 0s 473us/step - loss: 0.9607 - mean_squared_error: 0.9607\n",
      "Epoch 25/500\n",
      "195/195 [==============================] - 0s 469us/step - loss: 1.8768 - mean_squared_error: 1.8768\n",
      "Epoch 26/500\n",
      "195/195 [==============================] - 0s 466us/step - loss: 2.0301 - mean_squared_error: 2.0301\n",
      "Epoch 27/500\n",
      "195/195 [==============================] - 0s 463us/step - loss: 6.5470 - mean_squared_error: 6.5470\n",
      "Epoch 28/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 1.2541 - mean_squared_error: 1.2541\n",
      "Epoch 29/500\n",
      "195/195 [==============================] - 0s 462us/step - loss: 3.6326 - mean_squared_error: 3.6326\n",
      "Epoch 30/500\n",
      "195/195 [==============================] - 0s 462us/step - loss: 7.8475 - mean_squared_error: 7.8475\n",
      "Epoch 31/500\n",
      "195/195 [==============================] - 0s 467us/step - loss: 1.3212 - mean_squared_error: 1.3212\n",
      "Epoch 32/500\n",
      "195/195 [==============================] - 0s 469us/step - loss: 1.8156 - mean_squared_error: 1.8156\n",
      "Epoch 33/500\n",
      "195/195 [==============================] - 0s 469us/step - loss: 3.6993 - mean_squared_error: 3.6993\n",
      "Epoch 34/500\n",
      "195/195 [==============================] - 0s 471us/step - loss: 1.1965 - mean_squared_error: 1.1965\n",
      "Epoch 35/500\n",
      "195/195 [==============================] - 0s 467us/step - loss: 2.7279 - mean_squared_error: 2.7279\n",
      "Epoch 36/500\n",
      "195/195 [==============================] - 0s 471us/step - loss: 4.1348 - mean_squared_error: 4.1348\n",
      "Epoch 37/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 2.8993 - mean_squared_error: 2.8993\n",
      "Epoch 38/500\n",
      "195/195 [==============================] - 0s 467us/step - loss: 7.7310 - mean_squared_error: 7.7310\n",
      "Epoch 39/500\n",
      "195/195 [==============================] - 0s 464us/step - loss: 2.6828 - mean_squared_error: 2.6828\n",
      "Epoch 40/500\n",
      "195/195 [==============================] - 0s 465us/step - loss: 4.1270 - mean_squared_error: 4.1270\n",
      "Epoch 41/500\n",
      "195/195 [==============================] - 0s 466us/step - loss: 7.0921 - mean_squared_error: 7.0921\n",
      "Epoch 42/500\n",
      "195/195 [==============================] - 0s 470us/step - loss: 1.2927 - mean_squared_error: 1.2927\n",
      "Epoch 43/500\n",
      "195/195 [==============================] - 0s 467us/step - loss: 1.0128 - mean_squared_error: 1.0128\n",
      "Epoch 44/500\n",
      "195/195 [==============================] - 0s 468us/step - loss: 1.1829 - mean_squared_error: 1.1829\n",
      "Epoch 45/500\n",
      "195/195 [==============================] - 0s 471us/step - loss: 0.7270 - mean_squared_error: 0.7270\n",
      "Epoch 46/500\n",
      "195/195 [==============================] - 0s 477us/step - loss: 1.3299 - mean_squared_error: 1.3299\n",
      "Epoch 47/500\n",
      "195/195 [==============================] - 0s 474us/step - loss: 0.8880 - mean_squared_error: 0.8880\n",
      "Epoch 48/500\n",
      "195/195 [==============================] - 0s 471us/step - loss: 1.1101 - mean_squared_error: 1.1101\n",
      "Epoch 49/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.9369 - mean_squared_error: 0.9369\n",
      "Epoch 50/500\n",
      "195/195 [==============================] - 0s 472us/step - loss: 0.8308 - mean_squared_error: 0.8308\n",
      "Epoch 51/500\n",
      "195/195 [==============================] - 0s 469us/step - loss: 1.3588 - mean_squared_error: 1.3588\n",
      "Epoch 52/500\n",
      "195/195 [==============================] - 0s 465us/step - loss: 0.8570 - mean_squared_error: 0.8570\n",
      "Epoch 53/500\n",
      "195/195 [==============================] - 0s 462us/step - loss: 0.5812 - mean_squared_error: 0.5812\n",
      "Epoch 54/500\n",
      "195/195 [==============================] - 0s 487us/step - loss: 0.6791 - mean_squared_error: 0.6791\n",
      "Epoch 55/500\n",
      "195/195 [==============================] - 0s 476us/step - loss: 0.8985 - mean_squared_error: 0.8985\n",
      "Epoch 56/500\n",
      "195/195 [==============================] - 0s 464us/step - loss: 0.8275 - mean_squared_error: 0.8275\n",
      "Epoch 57/500\n",
      "195/195 [==============================] - 0s 462us/step - loss: 0.5836 - mean_squared_error: 0.5836\n",
      "Epoch 58/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.7353 - mean_squared_error: 0.7353\n",
      "Epoch 59/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.5590 - mean_squared_error: 0.5590\n",
      "Epoch 60/500\n",
      "195/195 [==============================] - 0s 463us/step - loss: 0.7020 - mean_squared_error: 0.7020\n",
      "Epoch 61/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.6642 - mean_squared_error: 0.6642\n",
      "Epoch 62/500\n",
      "195/195 [==============================] - 0s 462us/step - loss: 0.5565 - mean_squared_error: 0.5565\n",
      "Epoch 63/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.4541 - mean_squared_error: 0.4541\n",
      "Epoch 64/500\n",
      "195/195 [==============================] - 0s 462us/step - loss: 0.4614 - mean_squared_error: 0.4614\n",
      "Epoch 65/500\n",
      "195/195 [==============================] - 0s 474us/step - loss: 0.7658 - mean_squared_error: 0.7658\n",
      "Epoch 66/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.4944 - mean_squared_error: 0.4944\n",
      "Epoch 67/500\n",
      "195/195 [==============================] - 0s 467us/step - loss: 0.4263 - mean_squared_error: 0.4263\n",
      "Epoch 68/500\n",
      "195/195 [==============================] - 0s 463us/step - loss: 0.4350 - mean_squared_error: 0.4350\n",
      "Epoch 69/500\n",
      "195/195 [==============================] - 0s 486us/step - loss: 0.4318 - mean_squared_error: 0.4318\n",
      "Epoch 70/500\n",
      "195/195 [==============================] - 0s 469us/step - loss: 0.3221 - mean_squared_error: 0.3221\n",
      "Epoch 71/500\n",
      "195/195 [==============================] - 0s 450us/step - loss: 0.4136 - mean_squared_error: 0.4136\n",
      "Epoch 72/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.4052 - mean_squared_error: 0.4052\n",
      "Epoch 73/500\n",
      "195/195 [==============================] - 0s 463us/step - loss: 0.3436 - mean_squared_error: 0.3436\n",
      "Epoch 74/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.3839 - mean_squared_error: 0.3839\n",
      "Epoch 75/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.4089 - mean_squared_error: 0.4089\n",
      "Epoch 76/500\n",
      "195/195 [==============================] - 0s 451us/step - loss: 0.3701 - mean_squared_error: 0.3701\n",
      "Epoch 77/500\n",
      "195/195 [==============================] - 0s 452us/step - loss: 0.3503 - mean_squared_error: 0.3503\n",
      "Epoch 78/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3532 - mean_squared_error: 0.3532\n",
      "Epoch 79/500\n",
      "195/195 [==============================] - 0s 466us/step - loss: 0.3878 - mean_squared_error: 0.3878\n",
      "Epoch 80/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.3487 - mean_squared_error: 0.3487\n",
      "Epoch 81/500\n",
      "195/195 [==============================] - 0s 450us/step - loss: 0.3758 - mean_squared_error: 0.3758\n",
      "Epoch 82/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3606 - mean_squared_error: 0.3606\n",
      "Epoch 83/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.4106 - mean_squared_error: 0.4106\n",
      "Epoch 84/500\n",
      "195/195 [==============================] - 0s 462us/step - loss: 0.3767 - mean_squared_error: 0.3767\n",
      "Epoch 85/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3443 - mean_squared_error: 0.3443\n",
      "Epoch 86/500\n",
      "195/195 [==============================] - 0s 453us/step - loss: 0.3538 - mean_squared_error: 0.3538\n",
      "Epoch 87/500\n",
      "195/195 [==============================] - 0s 463us/step - loss: 0.3743 - mean_squared_error: 0.3743\n",
      "Epoch 88/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.3445 - mean_squared_error: 0.3445\n",
      "Epoch 89/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.3636 - mean_squared_error: 0.3636\n",
      "Epoch 90/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3830 - mean_squared_error: 0.3830\n",
      "Epoch 91/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.4565 - mean_squared_error: 0.4565\n",
      "Epoch 92/500\n",
      "195/195 [==============================] - 0s 462us/step - loss: 0.3487 - mean_squared_error: 0.3487\n",
      "Epoch 93/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.4231 - mean_squared_error: 0.4231\n",
      "Epoch 94/500\n",
      "195/195 [==============================] - 0s 464us/step - loss: 0.3583 - mean_squared_error: 0.3583\n",
      "Epoch 95/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.4063 - mean_squared_error: 0.4063\n",
      "Epoch 96/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3552 - mean_squared_error: 0.3552\n",
      "Epoch 97/500\n",
      "195/195 [==============================] - 0s 521us/step - loss: 0.3899 - mean_squared_error: 0.3899\n",
      "Epoch 98/500\n",
      "195/195 [==============================] - 0s 645us/step - loss: 0.3738 - mean_squared_error: 0.3738\n",
      "Epoch 99/500\n",
      "195/195 [==============================] - 0s 470us/step - loss: 0.3668 - mean_squared_error: 0.3668\n",
      "Epoch 100/500\n",
      "195/195 [==============================] - 0s 446us/step - loss: 0.4148 - mean_squared_error: 0.4148\n",
      "Epoch 101/500\n",
      "195/195 [==============================] - 0s 452us/step - loss: 0.3338 - mean_squared_error: 0.3338\n",
      "Epoch 102/500\n",
      "195/195 [==============================] - 0s 462us/step - loss: 0.4591 - mean_squared_error: 0.4591\n",
      "Epoch 103/500\n",
      "195/195 [==============================] - 0s 451us/step - loss: 0.3946 - mean_squared_error: 0.3946\n",
      "Epoch 104/500\n",
      "195/195 [==============================] - 0s 452us/step - loss: 0.3509 - mean_squared_error: 0.3509\n",
      "Epoch 105/500\n",
      "195/195 [==============================] - 0s 445us/step - loss: 0.3737 - mean_squared_error: 0.3737\n",
      "Epoch 106/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3673 - mean_squared_error: 0.3673\n",
      "Epoch 107/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3980 - mean_squared_error: 0.3980\n",
      "Epoch 108/500\n",
      "195/195 [==============================] - 0s 474us/step - loss: 0.3545 - mean_squared_error: 0.3545\n",
      "Epoch 109/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3709 - mean_squared_error: 0.3709\n",
      "Epoch 110/500\n",
      "195/195 [==============================] - 0s 462us/step - loss: 0.3990 - mean_squared_error: 0.3990\n",
      "Epoch 111/500\n",
      "195/195 [==============================] - 0s 468us/step - loss: 0.3831 - mean_squared_error: 0.3831\n",
      "Epoch 112/500\n",
      "195/195 [==============================] - 0s 450us/step - loss: 0.4228 - mean_squared_error: 0.4228\n",
      "Epoch 113/500\n",
      "195/195 [==============================] - 0s 452us/step - loss: 0.4088 - mean_squared_error: 0.4088\n",
      "Epoch 114/500\n",
      "195/195 [==============================] - 0s 450us/step - loss: 0.3558 - mean_squared_error: 0.3558\n",
      "Epoch 115/500\n",
      "195/195 [==============================] - 0s 451us/step - loss: 0.3618 - mean_squared_error: 0.3618\n",
      "Epoch 116/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3717 - mean_squared_error: 0.3717\n",
      "Epoch 117/500\n",
      "195/195 [==============================] - 0s 444us/step - loss: 0.4271 - mean_squared_error: 0.4271\n",
      "Epoch 118/500\n",
      "195/195 [==============================] - 0s 450us/step - loss: 0.3765 - mean_squared_error: 0.3765\n",
      "Epoch 119/500\n",
      "195/195 [==============================] - 0s 451us/step - loss: 0.3944 - mean_squared_error: 0.3944\n",
      "Epoch 120/500\n",
      "195/195 [==============================] - 0s 451us/step - loss: 0.3681 - mean_squared_error: 0.3681\n",
      "Epoch 121/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.4066 - mean_squared_error: 0.4066\n",
      "Epoch 122/500\n",
      "195/195 [==============================] - 0s 506us/step - loss: 0.3814 - mean_squared_error: 0.3814\n",
      "Epoch 123/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.4179 - mean_squared_error: 0.4179\n",
      "Epoch 124/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.3900 - mean_squared_error: 0.3900\n",
      "Epoch 125/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.3414 - mean_squared_error: 0.3414\n",
      "Epoch 126/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.4178 - mean_squared_error: 0.4178\n",
      "Epoch 127/500\n",
      "195/195 [==============================] - 0s 453us/step - loss: 0.4684 - mean_squared_error: 0.4684\n",
      "Epoch 128/500\n",
      "195/195 [==============================] - 0s 446us/step - loss: 0.3913 - mean_squared_error: 0.3913\n",
      "Epoch 129/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.4161 - mean_squared_error: 0.4161\n",
      "Epoch 130/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3436 - mean_squared_error: 0.3436\n",
      "Epoch 131/500\n",
      "195/195 [==============================] - 0s 467us/step - loss: 0.3638 - mean_squared_error: 0.3638\n",
      "Epoch 132/500\n",
      "195/195 [==============================] - 0s 451us/step - loss: 0.4364 - mean_squared_error: 0.4364\n",
      "Epoch 133/500\n",
      "195/195 [==============================] - 0s 463us/step - loss: 0.4071 - mean_squared_error: 0.4071\n",
      "Epoch 134/500\n",
      "195/195 [==============================] - 0s 470us/step - loss: 0.4353 - mean_squared_error: 0.4353\n",
      "Epoch 135/500\n",
      "195/195 [==============================] - 0s 463us/step - loss: 0.3579 - mean_squared_error: 0.3579\n",
      "Epoch 136/500\n",
      "195/195 [==============================] - 0s 495us/step - loss: 0.4921 - mean_squared_error: 0.4921\n",
      "Epoch 137/500\n",
      "195/195 [==============================] - 0s 469us/step - loss: 0.3540 - mean_squared_error: 0.3540\n",
      "Epoch 138/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3805 - mean_squared_error: 0.3805\n",
      "Epoch 139/500\n",
      "195/195 [==============================] - 0s 453us/step - loss: 0.4060 - mean_squared_error: 0.4060\n",
      "Epoch 140/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.4473 - mean_squared_error: 0.4473\n",
      "Epoch 141/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3975 - mean_squared_error: 0.3975\n",
      "Epoch 142/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3856 - mean_squared_error: 0.3856\n",
      "Epoch 143/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 462us/step - loss: 0.3752 - mean_squared_error: 0.3752\n",
      "Epoch 144/500\n",
      "195/195 [==============================] - 0s 446us/step - loss: 0.3959 - mean_squared_error: 0.3959\n",
      "Epoch 145/500\n",
      "195/195 [==============================] - 0s 445us/step - loss: 0.3253 - mean_squared_error: 0.3253\n",
      "Epoch 146/500\n",
      "195/195 [==============================] - 0s 446us/step - loss: 0.3575 - mean_squared_error: 0.3575\n",
      "Epoch 147/500\n",
      "195/195 [==============================] - 0s 440us/step - loss: 0.4661 - mean_squared_error: 0.4661\n",
      "Epoch 148/500\n",
      "195/195 [==============================] - 0s 442us/step - loss: 0.3956 - mean_squared_error: 0.3956\n",
      "Epoch 149/500\n",
      "195/195 [==============================] - 0s 444us/step - loss: 0.3272 - mean_squared_error: 0.3272\n",
      "Epoch 150/500\n",
      "195/195 [==============================] - 0s 451us/step - loss: 0.4162 - mean_squared_error: 0.4162\n",
      "Epoch 151/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3937 - mean_squared_error: 0.3937\n",
      "Epoch 152/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.3784 - mean_squared_error: 0.3784\n",
      "Epoch 153/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.3809 - mean_squared_error: 0.3809\n",
      "Epoch 154/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3683 - mean_squared_error: 0.3683\n",
      "Epoch 155/500\n",
      "195/195 [==============================] - 0s 471us/step - loss: 0.3786 - mean_squared_error: 0.3786\n",
      "Epoch 156/500\n",
      "195/195 [==============================] - 0s 469us/step - loss: 0.3859 - mean_squared_error: 0.3859\n",
      "Epoch 157/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3950 - mean_squared_error: 0.3950\n",
      "Epoch 158/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3614 - mean_squared_error: 0.3614\n",
      "Epoch 159/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.3401 - mean_squared_error: 0.3401\n",
      "Epoch 160/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3465 - mean_squared_error: 0.3465\n",
      "Epoch 161/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3374 - mean_squared_error: 0.3374\n",
      "Epoch 162/500\n",
      "195/195 [==============================] - 0s 464us/step - loss: 0.3569 - mean_squared_error: 0.3569\n",
      "Epoch 163/500\n",
      "195/195 [==============================] - 0s 464us/step - loss: 0.3852 - mean_squared_error: 0.3852\n",
      "Epoch 164/500\n",
      "195/195 [==============================] - 0s 450us/step - loss: 0.3521 - mean_squared_error: 0.3521\n",
      "Epoch 165/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3334 - mean_squared_error: 0.3334\n",
      "Epoch 166/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.4037 - mean_squared_error: 0.4037\n",
      "Epoch 167/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3677 - mean_squared_error: 0.3677\n",
      "Epoch 168/500\n",
      "195/195 [==============================] - 0s 462us/step - loss: 0.4254 - mean_squared_error: 0.4254\n",
      "Epoch 169/500\n",
      "195/195 [==============================] - 0s 469us/step - loss: 0.3759 - mean_squared_error: 0.3759\n",
      "Epoch 170/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.4201 - mean_squared_error: 0.4201\n",
      "Epoch 171/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3710 - mean_squared_error: 0.3710\n",
      "Epoch 172/500\n",
      "195/195 [==============================] - 0s 462us/step - loss: 0.3886 - mean_squared_error: 0.3886\n",
      "Epoch 173/500\n",
      "195/195 [==============================] - 0s 468us/step - loss: 0.4928 - mean_squared_error: 0.4928\n",
      "Epoch 174/500\n",
      "195/195 [==============================] - 0s 474us/step - loss: 0.4621 - mean_squared_error: 0.4621\n",
      "Epoch 175/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.3612 - mean_squared_error: 0.3612\n",
      "Epoch 176/500\n",
      "195/195 [==============================] - 0s 462us/step - loss: 0.3501 - mean_squared_error: 0.3501\n",
      "Epoch 177/500\n",
      "195/195 [==============================] - 0s 466us/step - loss: 0.3859 - mean_squared_error: 0.3859\n",
      "Epoch 178/500\n",
      "195/195 [==============================] - 0s 464us/step - loss: 0.3693 - mean_squared_error: 0.3693\n",
      "Epoch 179/500\n",
      "195/195 [==============================] - 0s 488us/step - loss: 0.4028 - mean_squared_error: 0.4028\n",
      "Epoch 180/500\n",
      "195/195 [==============================] - 0s 475us/step - loss: 0.3972 - mean_squared_error: 0.3972\n",
      "Epoch 181/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3533 - mean_squared_error: 0.3533\n",
      "Epoch 182/500\n",
      "195/195 [==============================] - 0s 476us/step - loss: 0.3310 - mean_squared_error: 0.3310\n",
      "Epoch 183/500\n",
      "195/195 [==============================] - 0s 642us/step - loss: 0.3544 - mean_squared_error: 0.3544\n",
      "Epoch 184/500\n",
      "195/195 [==============================] - 0s 597us/step - loss: 0.3845 - mean_squared_error: 0.3845\n",
      "Epoch 185/500\n",
      "195/195 [==============================] - 0s 490us/step - loss: 0.3512 - mean_squared_error: 0.3512\n",
      "Epoch 186/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3491 - mean_squared_error: 0.3491\n",
      "Epoch 187/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3309 - mean_squared_error: 0.3309\n",
      "Epoch 188/500\n",
      "195/195 [==============================] - 0s 492us/step - loss: 0.3482 - mean_squared_error: 0.3482\n",
      "Epoch 189/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3518 - mean_squared_error: 0.3518\n",
      "Epoch 190/500\n",
      "195/195 [==============================] - 0s 669us/step - loss: 0.4071 - mean_squared_error: 0.4071\n",
      "Epoch 191/500\n",
      "195/195 [==============================] - 0s 634us/step - loss: 0.3964 - mean_squared_error: 0.3964\n",
      "Epoch 192/500\n",
      "195/195 [==============================] - 0s 743us/step - loss: 0.4355 - mean_squared_error: 0.4355\n",
      "Epoch 193/500\n",
      "195/195 [==============================] - 0s 1ms/step - loss: 0.3295 - mean_squared_error: 0.3295\n",
      "Epoch 194/500\n",
      "195/195 [==============================] - 0s 493us/step - loss: 0.3724 - mean_squared_error: 0.3724\n",
      "Epoch 195/500\n",
      "195/195 [==============================] - 0s 506us/step - loss: 0.3682 - mean_squared_error: 0.3682\n",
      "Epoch 196/500\n",
      "195/195 [==============================] - 0s 494us/step - loss: 0.3606 - mean_squared_error: 0.3606\n",
      "Epoch 197/500\n",
      "195/195 [==============================] - 0s 496us/step - loss: 0.3963 - mean_squared_error: 0.3963\n",
      "Epoch 198/500\n",
      "195/195 [==============================] - 0s 479us/step - loss: 0.4091 - mean_squared_error: 0.4091\n",
      "Epoch 199/500\n",
      "195/195 [==============================] - 0s 476us/step - loss: 0.3773 - mean_squared_error: 0.3773\n",
      "Epoch 200/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.3807 - mean_squared_error: 0.3807\n",
      "Epoch 201/500\n",
      "195/195 [==============================] - 0s 476us/step - loss: 0.4005 - mean_squared_error: 0.4005\n",
      "Epoch 202/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.4206 - mean_squared_error: 0.4206\n",
      "Epoch 203/500\n",
      "195/195 [==============================] - 0s 503us/step - loss: 0.3435 - mean_squared_error: 0.3435\n",
      "Epoch 204/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.3815 - mean_squared_error: 0.3815\n",
      "Epoch 205/500\n",
      "195/195 [==============================] - 0s 470us/step - loss: 0.3492 - mean_squared_error: 0.3492\n",
      "Epoch 206/500\n",
      "195/195 [==============================] - 0s 504us/step - loss: 0.3458 - mean_squared_error: 0.3458\n",
      "Epoch 207/500\n",
      "195/195 [==============================] - 0s 468us/step - loss: 0.3696 - mean_squared_error: 0.3696\n",
      "Epoch 208/500\n",
      "195/195 [==============================] - 0s 476us/step - loss: 0.4136 - mean_squared_error: 0.4136\n",
      "Epoch 209/500\n",
      "195/195 [==============================] - 0s 474us/step - loss: 0.3744 - mean_squared_error: 0.3744\n",
      "Epoch 210/500\n",
      "195/195 [==============================] - 0s 472us/step - loss: 0.4067 - mean_squared_error: 0.4067\n",
      "Epoch 211/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3705 - mean_squared_error: 0.3705\n",
      "Epoch 212/500\n",
      "195/195 [==============================] - 0s 597us/step - loss: 0.3599 - mean_squared_error: 0.3599\n",
      "Epoch 213/500\n",
      "195/195 [==============================] - 0s 599us/step - loss: 0.3304 - mean_squared_error: 0.3304\n",
      "Epoch 214/500\n",
      "195/195 [==============================] - 0s 582us/step - loss: 0.3734 - mean_squared_error: 0.3734\n",
      "Epoch 215/500\n",
      "195/195 [==============================] - 0s 547us/step - loss: 0.3578 - mean_squared_error: 0.3578\n",
      "Epoch 216/500\n",
      "195/195 [==============================] - 0s 586us/step - loss: 0.3843 - mean_squared_error: 0.3843\n",
      "Epoch 217/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3240 - mean_squared_error: 0.3240\n",
      "Epoch 218/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.3440 - mean_squared_error: 0.3440\n",
      "Epoch 219/500\n",
      "195/195 [==============================] - 0s 533us/step - loss: 0.3458 - mean_squared_error: 0.3458\n",
      "Epoch 220/500\n",
      "195/195 [==============================] - 0s 486us/step - loss: 0.3475 - mean_squared_error: 0.3475\n",
      "Epoch 221/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3871 - mean_squared_error: 0.3871\n",
      "Epoch 222/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.3794 - mean_squared_error: 0.3794\n",
      "Epoch 223/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3705 - mean_squared_error: 0.3705\n",
      "Epoch 224/500\n",
      "195/195 [==============================] - 0s 453us/step - loss: 0.4578 - mean_squared_error: 0.4578\n",
      "Epoch 225/500\n",
      "195/195 [==============================] - 0s 466us/step - loss: 0.3880 - mean_squared_error: 0.3880\n",
      "Epoch 226/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.4494 - mean_squared_error: 0.4494\n",
      "Epoch 227/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3791 - mean_squared_error: 0.3791\n",
      "Epoch 228/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3654 - mean_squared_error: 0.3654\n",
      "Epoch 229/500\n",
      "195/195 [==============================] - 0s 453us/step - loss: 0.3709 - mean_squared_error: 0.3709\n",
      "Epoch 230/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3385 - mean_squared_error: 0.3385\n",
      "Epoch 231/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3480 - mean_squared_error: 0.3480\n",
      "Epoch 232/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3629 - mean_squared_error: 0.3629\n",
      "Epoch 233/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3329 - mean_squared_error: 0.3329\n",
      "Epoch 234/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.3672 - mean_squared_error: 0.3672\n",
      "Epoch 235/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3422 - mean_squared_error: 0.3422\n",
      "Epoch 236/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3894 - mean_squared_error: 0.3894\n",
      "Epoch 237/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3897 - mean_squared_error: 0.3897\n",
      "Epoch 238/500\n",
      "195/195 [==============================] - 0s 471us/step - loss: 0.3895 - mean_squared_error: 0.3895\n",
      "Epoch 239/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3658 - mean_squared_error: 0.3658\n",
      "Epoch 240/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3638 - mean_squared_error: 0.3638\n",
      "Epoch 241/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.3621 - mean_squared_error: 0.3621\n",
      "Epoch 242/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.3168 - mean_squared_error: 0.3168\n",
      "Epoch 243/500\n",
      "195/195 [==============================] - 0s 467us/step - loss: 0.3552 - mean_squared_error: 0.3552\n",
      "Epoch 244/500\n",
      "195/195 [==============================] - 0s 453us/step - loss: 0.3318 - mean_squared_error: 0.3318\n",
      "Epoch 245/500\n",
      "195/195 [==============================] - 0s 451us/step - loss: 0.3538 - mean_squared_error: 0.3538\n",
      "Epoch 246/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.3605 - mean_squared_error: 0.3605\n",
      "Epoch 247/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3855 - mean_squared_error: 0.3855\n",
      "Epoch 248/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.3321 - mean_squared_error: 0.3321\n",
      "Epoch 249/500\n",
      "195/195 [==============================] - 0s 468us/step - loss: 0.3668 - mean_squared_error: 0.3668\n",
      "Epoch 250/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3207 - mean_squared_error: 0.3207\n",
      "Epoch 251/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.4076 - mean_squared_error: 0.4076\n",
      "Epoch 252/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3331 - mean_squared_error: 0.3331\n",
      "Epoch 253/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.3049 - mean_squared_error: 0.3049\n",
      "Epoch 254/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3481 - mean_squared_error: 0.3481\n",
      "Epoch 255/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3827 - mean_squared_error: 0.3827\n",
      "Epoch 256/500\n",
      "195/195 [==============================] - 0s 470us/step - loss: 0.3429 - mean_squared_error: 0.3429\n",
      "Epoch 257/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.4179 - mean_squared_error: 0.4179\n",
      "Epoch 258/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.3958 - mean_squared_error: 0.3958\n",
      "Epoch 259/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.2954 - mean_squared_error: 0.2954\n",
      "Epoch 260/500\n",
      "195/195 [==============================] - 0s 465us/step - loss: 0.3587 - mean_squared_error: 0.3587\n",
      "Epoch 261/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.3525 - mean_squared_error: 0.3525\n",
      "Epoch 262/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3400 - mean_squared_error: 0.3400\n",
      "Epoch 263/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3400 - mean_squared_error: 0.3400\n",
      "Epoch 264/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3148 - mean_squared_error: 0.3148\n",
      "Epoch 265/500\n",
      "195/195 [==============================] - 0s 464us/step - loss: 0.2966 - mean_squared_error: 0.2966\n",
      "Epoch 266/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.4200 - mean_squared_error: 0.4200\n",
      "Epoch 267/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3430 - mean_squared_error: 0.3430\n",
      "Epoch 268/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.3567 - mean_squared_error: 0.3567\n",
      "Epoch 269/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.3787 - mean_squared_error: 0.3787\n",
      "Epoch 270/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3785 - mean_squared_error: 0.3785\n",
      "Epoch 271/500\n",
      "195/195 [==============================] - 0s 463us/step - loss: 0.3071 - mean_squared_error: 0.3071\n",
      "Epoch 272/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3707 - mean_squared_error: 0.3707\n",
      "Epoch 273/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3560 - mean_squared_error: 0.3560\n",
      "Epoch 274/500\n",
      "195/195 [==============================] - 0s 463us/step - loss: 0.3450 - mean_squared_error: 0.3450\n",
      "Epoch 275/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.3430 - mean_squared_error: 0.3430\n",
      "Epoch 276/500\n",
      "195/195 [==============================] - 0s 466us/step - loss: 0.3561 - mean_squared_error: 0.3561\n",
      "Epoch 277/500\n",
      "195/195 [==============================] - 0s 462us/step - loss: 0.3430 - mean_squared_error: 0.3430\n",
      "Epoch 278/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3480 - mean_squared_error: 0.3480\n",
      "Epoch 279/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3451 - mean_squared_error: 0.3451\n",
      "Epoch 280/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3411 - mean_squared_error: 0.3411\n",
      "Epoch 281/500\n",
      "195/195 [==============================] - 0s 462us/step - loss: 0.3974 - mean_squared_error: 0.3974\n",
      "Epoch 282/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3346 - mean_squared_error: 0.3346\n",
      "Epoch 283/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.3610 - mean_squared_error: 0.3610\n",
      "Epoch 284/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3194 - mean_squared_error: 0.3194\n",
      "Epoch 285/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 461us/step - loss: 0.3371 - mean_squared_error: 0.3371\n",
      "Epoch 286/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3854 - mean_squared_error: 0.3854\n",
      "Epoch 287/500\n",
      "195/195 [==============================] - 0s 453us/step - loss: 0.3386 - mean_squared_error: 0.3386\n",
      "Epoch 288/500\n",
      "195/195 [==============================] - 0s 465us/step - loss: 0.3060 - mean_squared_error: 0.3060\n",
      "Epoch 289/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.3740 - mean_squared_error: 0.3740\n",
      "Epoch 290/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.3454 - mean_squared_error: 0.3454\n",
      "Epoch 291/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3144 - mean_squared_error: 0.3144\n",
      "Epoch 292/500\n",
      "195/195 [==============================] - 0s 453us/step - loss: 0.3081 - mean_squared_error: 0.3081\n",
      "Epoch 293/500\n",
      "195/195 [==============================] - 0s 463us/step - loss: 0.3559 - mean_squared_error: 0.3559\n",
      "Epoch 294/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3555 - mean_squared_error: 0.3555\n",
      "Epoch 295/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3412 - mean_squared_error: 0.3412\n",
      "Epoch 296/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3505 - mean_squared_error: 0.3505\n",
      "Epoch 297/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3693 - mean_squared_error: 0.3693\n",
      "Epoch 298/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3767 - mean_squared_error: 0.3767\n",
      "Epoch 299/500\n",
      "195/195 [==============================] - 0s 462us/step - loss: 0.3489 - mean_squared_error: 0.3489\n",
      "Epoch 300/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.3312 - mean_squared_error: 0.3312\n",
      "Epoch 301/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3324 - mean_squared_error: 0.3324\n",
      "Epoch 302/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.3612 - mean_squared_error: 0.3612\n",
      "Epoch 303/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.3550 - mean_squared_error: 0.3550\n",
      "Epoch 304/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.4260 - mean_squared_error: 0.4260\n",
      "Epoch 305/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3588 - mean_squared_error: 0.3588\n",
      "Epoch 306/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.3831 - mean_squared_error: 0.3831\n",
      "Epoch 307/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3818 - mean_squared_error: 0.3818\n",
      "Epoch 308/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.4031 - mean_squared_error: 0.4031\n",
      "Epoch 309/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.2988 - mean_squared_error: 0.2988\n",
      "Epoch 310/500\n",
      "195/195 [==============================] - 0s 467us/step - loss: 0.3850 - mean_squared_error: 0.3850\n",
      "Epoch 311/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.3250 - mean_squared_error: 0.3250\n",
      "Epoch 312/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3122 - mean_squared_error: 0.3122\n",
      "Epoch 313/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.3364 - mean_squared_error: 0.3364\n",
      "Epoch 314/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3704 - mean_squared_error: 0.3704\n",
      "Epoch 315/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3233 - mean_squared_error: 0.3233\n",
      "Epoch 316/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3853 - mean_squared_error: 0.3853\n",
      "Epoch 317/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3415 - mean_squared_error: 0.3415\n",
      "Epoch 318/500\n",
      "195/195 [==============================] - 0s 452us/step - loss: 0.3409 - mean_squared_error: 0.3409\n",
      "Epoch 319/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3228 - mean_squared_error: 0.3228\n",
      "Epoch 320/500\n",
      "195/195 [==============================] - 0s 451us/step - loss: 0.3292 - mean_squared_error: 0.3292\n",
      "Epoch 321/500\n",
      "195/195 [==============================] - 0s 463us/step - loss: 0.2913 - mean_squared_error: 0.2913\n",
      "Epoch 322/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3834 - mean_squared_error: 0.3834\n",
      "Epoch 323/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.3778 - mean_squared_error: 0.3778\n",
      "Epoch 324/500\n",
      "195/195 [==============================] - 0s 526us/step - loss: 0.3733 - mean_squared_error: 0.3733\n",
      "Epoch 325/500\n",
      "195/195 [==============================] - 0s 463us/step - loss: 0.3265 - mean_squared_error: 0.3265\n",
      "Epoch 326/500\n",
      "195/195 [==============================] - 0s 464us/step - loss: 0.3720 - mean_squared_error: 0.3720\n",
      "Epoch 327/500\n",
      "195/195 [==============================] - 0s 468us/step - loss: 0.3839 - mean_squared_error: 0.3839\n",
      "Epoch 328/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.3405 - mean_squared_error: 0.3405\n",
      "Epoch 329/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3993 - mean_squared_error: 0.3993\n",
      "Epoch 330/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3322 - mean_squared_error: 0.3322\n",
      "Epoch 331/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.3474 - mean_squared_error: 0.3474\n",
      "Epoch 332/500\n",
      "195/195 [==============================] - 0s 465us/step - loss: 0.3344 - mean_squared_error: 0.3344\n",
      "Epoch 333/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3226 - mean_squared_error: 0.3226\n",
      "Epoch 334/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3663 - mean_squared_error: 0.3663\n",
      "Epoch 335/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3618 - mean_squared_error: 0.3618\n",
      "Epoch 336/500\n",
      "195/195 [==============================] - 0s 468us/step - loss: 0.3576 - mean_squared_error: 0.3576\n",
      "Epoch 337/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3561 - mean_squared_error: 0.3561\n",
      "Epoch 338/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3386 - mean_squared_error: 0.3386\n",
      "Epoch 339/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.3317 - mean_squared_error: 0.3317\n",
      "Epoch 340/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3252 - mean_squared_error: 0.3252\n",
      "Epoch 341/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3610 - mean_squared_error: 0.3610\n",
      "Epoch 342/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.3443 - mean_squared_error: 0.3443\n",
      "Epoch 343/500\n",
      "195/195 [==============================] - 0s 466us/step - loss: 0.3261 - mean_squared_error: 0.3261\n",
      "Epoch 344/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3144 - mean_squared_error: 0.3144\n",
      "Epoch 345/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3704 - mean_squared_error: 0.3704\n",
      "Epoch 346/500\n",
      "195/195 [==============================] - 0s 453us/step - loss: 0.3493 - mean_squared_error: 0.3493\n",
      "Epoch 347/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3244 - mean_squared_error: 0.3244\n",
      "Epoch 348/500\n",
      "195/195 [==============================] - 0s 468us/step - loss: 0.3504 - mean_squared_error: 0.3504\n",
      "Epoch 349/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3492 - mean_squared_error: 0.3492\n",
      "Epoch 350/500\n",
      "195/195 [==============================] - 0s 462us/step - loss: 0.3441 - mean_squared_error: 0.3441\n",
      "Epoch 351/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.3434 - mean_squared_error: 0.3434\n",
      "Epoch 352/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3442 - mean_squared_error: 0.3442\n",
      "Epoch 353/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3476 - mean_squared_error: 0.3476\n",
      "Epoch 354/500\n",
      "195/195 [==============================] - 0s 463us/step - loss: 0.3124 - mean_squared_error: 0.3124\n",
      "Epoch 355/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.3473 - mean_squared_error: 0.3473\n",
      "Epoch 356/500\n",
      "195/195 [==============================] - 0s 462us/step - loss: 0.3545 - mean_squared_error: 0.3545\n",
      "Epoch 357/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3133 - mean_squared_error: 0.3133\n",
      "Epoch 358/500\n",
      "195/195 [==============================] - 0s 450us/step - loss: 0.3476 - mean_squared_error: 0.3476\n",
      "Epoch 359/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3553 - mean_squared_error: 0.3553\n",
      "Epoch 360/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.3250 - mean_squared_error: 0.3250\n",
      "Epoch 361/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.3166 - mean_squared_error: 0.3166\n",
      "Epoch 362/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.3969 - mean_squared_error: 0.3969\n",
      "Epoch 363/500\n",
      "195/195 [==============================] - 0s 452us/step - loss: 0.3761 - mean_squared_error: 0.3761\n",
      "Epoch 364/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3356 - mean_squared_error: 0.3356\n",
      "Epoch 365/500\n",
      "195/195 [==============================] - 0s 463us/step - loss: 0.3733 - mean_squared_error: 0.3733\n",
      "Epoch 366/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.3534 - mean_squared_error: 0.3534\n",
      "Epoch 367/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3284 - mean_squared_error: 0.3284\n",
      "Epoch 368/500\n",
      "195/195 [==============================] - 0s 453us/step - loss: 0.3523 - mean_squared_error: 0.3523\n",
      "Epoch 369/500\n",
      "195/195 [==============================] - 0s 452us/step - loss: 0.3385 - mean_squared_error: 0.3385\n",
      "Epoch 370/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3688 - mean_squared_error: 0.3688\n",
      "Epoch 371/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3474 - mean_squared_error: 0.3474\n",
      "Epoch 372/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3237 - mean_squared_error: 0.3237\n",
      "Epoch 373/500\n",
      "195/195 [==============================] - 0s 452us/step - loss: 0.3601 - mean_squared_error: 0.3601\n",
      "Epoch 374/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.3290 - mean_squared_error: 0.3290\n",
      "Epoch 375/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3493 - mean_squared_error: 0.3493\n",
      "Epoch 376/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.3398 - mean_squared_error: 0.3398\n",
      "Epoch 377/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3571 - mean_squared_error: 0.3571\n",
      "Epoch 378/500\n",
      "195/195 [==============================] - 0s 451us/step - loss: 0.3353 - mean_squared_error: 0.3353\n",
      "Epoch 379/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3303 - mean_squared_error: 0.3303\n",
      "Epoch 380/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3735 - mean_squared_error: 0.3735\n",
      "Epoch 381/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.3478 - mean_squared_error: 0.3478\n",
      "Epoch 382/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3242 - mean_squared_error: 0.3242\n",
      "Epoch 383/500\n",
      "195/195 [==============================] - 0s 450us/step - loss: 0.3412 - mean_squared_error: 0.3412\n",
      "Epoch 384/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3198 - mean_squared_error: 0.3198\n",
      "Epoch 385/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3578 - mean_squared_error: 0.3578\n",
      "Epoch 386/500\n",
      "195/195 [==============================] - 0s 453us/step - loss: 0.3591 - mean_squared_error: 0.3591\n",
      "Epoch 387/500\n",
      "195/195 [==============================] - 0s 464us/step - loss: 0.3555 - mean_squared_error: 0.3555\n",
      "Epoch 388/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.3284 - mean_squared_error: 0.3284\n",
      "Epoch 389/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.3787 - mean_squared_error: 0.3787\n",
      "Epoch 390/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3174 - mean_squared_error: 0.3174\n",
      "Epoch 391/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.4053 - mean_squared_error: 0.4053\n",
      "Epoch 392/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3752 - mean_squared_error: 0.3752\n",
      "Epoch 393/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.3472 - mean_squared_error: 0.3472\n",
      "Epoch 394/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.3708 - mean_squared_error: 0.3708\n",
      "Epoch 395/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.4012 - mean_squared_error: 0.4012\n",
      "Epoch 396/500\n",
      "195/195 [==============================] - 0s 446us/step - loss: 0.3259 - mean_squared_error: 0.3259\n",
      "Epoch 397/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3491 - mean_squared_error: 0.3491\n",
      "Epoch 398/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3418 - mean_squared_error: 0.3418\n",
      "Epoch 399/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.3648 - mean_squared_error: 0.3648\n",
      "Epoch 400/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3368 - mean_squared_error: 0.3368\n",
      "Epoch 401/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.3730 - mean_squared_error: 0.3730\n",
      "Epoch 402/500\n",
      "195/195 [==============================] - 0s 473us/step - loss: 0.3157 - mean_squared_error: 0.3157\n",
      "Epoch 403/500\n",
      "195/195 [==============================] - 0s 463us/step - loss: 0.3363 - mean_squared_error: 0.3363\n",
      "Epoch 404/500\n",
      "195/195 [==============================] - 0s 465us/step - loss: 0.3341 - mean_squared_error: 0.3341\n",
      "Epoch 405/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.3621 - mean_squared_error: 0.3621\n",
      "Epoch 406/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3321 - mean_squared_error: 0.3321\n",
      "Epoch 407/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3878 - mean_squared_error: 0.3878\n",
      "Epoch 408/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.4001 - mean_squared_error: 0.4001\n",
      "Epoch 409/500\n",
      "195/195 [==============================] - 0s 463us/step - loss: 0.3544 - mean_squared_error: 0.3544\n",
      "Epoch 410/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.3777 - mean_squared_error: 0.3777\n",
      "Epoch 411/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3781 - mean_squared_error: 0.3781\n",
      "Epoch 412/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.3543 - mean_squared_error: 0.3543\n",
      "Epoch 413/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.3922 - mean_squared_error: 0.3922\n",
      "Epoch 414/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3169 - mean_squared_error: 0.3169\n",
      "Epoch 415/500\n",
      "195/195 [==============================] - 0s 468us/step - loss: 0.3567 - mean_squared_error: 0.3567\n",
      "Epoch 416/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3699 - mean_squared_error: 0.3699\n",
      "Epoch 417/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3078 - mean_squared_error: 0.3078\n",
      "Epoch 418/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3670 - mean_squared_error: 0.3670\n",
      "Epoch 419/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.3244 - mean_squared_error: 0.3244\n",
      "Epoch 420/500\n",
      "195/195 [==============================] - 0s 463us/step - loss: 0.3548 - mean_squared_error: 0.3548\n",
      "Epoch 421/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3547 - mean_squared_error: 0.3547\n",
      "Epoch 422/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3810 - mean_squared_error: 0.3810\n",
      "Epoch 423/500\n",
      "195/195 [==============================] - 0s 462us/step - loss: 0.3196 - mean_squared_error: 0.3196\n",
      "Epoch 424/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3781 - mean_squared_error: 0.3781\n",
      "Epoch 425/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3496 - mean_squared_error: 0.3496\n",
      "Epoch 426/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3166 - mean_squared_error: 0.3166\n",
      "Epoch 427/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 461us/step - loss: 0.3261 - mean_squared_error: 0.3261\n",
      "Epoch 428/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.3608 - mean_squared_error: 0.3608\n",
      "Epoch 429/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.3415 - mean_squared_error: 0.3415\n",
      "Epoch 430/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.3449 - mean_squared_error: 0.3449\n",
      "Epoch 431/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3366 - mean_squared_error: 0.3366\n",
      "Epoch 432/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3858 - mean_squared_error: 0.3858\n",
      "Epoch 433/500\n",
      "195/195 [==============================] - 0s 451us/step - loss: 0.3822 - mean_squared_error: 0.3822\n",
      "Epoch 434/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3119 - mean_squared_error: 0.3119\n",
      "Epoch 435/500\n",
      "195/195 [==============================] - 0s 476us/step - loss: 0.3436 - mean_squared_error: 0.3436\n",
      "Epoch 436/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3528 - mean_squared_error: 0.3528\n",
      "Epoch 437/500\n",
      "195/195 [==============================] - 0s 465us/step - loss: 0.3033 - mean_squared_error: 0.3033\n",
      "Epoch 438/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3879 - mean_squared_error: 0.3879\n",
      "Epoch 439/500\n",
      "195/195 [==============================] - 0s 453us/step - loss: 0.3277 - mean_squared_error: 0.3277\n",
      "Epoch 440/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.4086 - mean_squared_error: 0.4086\n",
      "Epoch 441/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.3286 - mean_squared_error: 0.3286\n",
      "Epoch 442/500\n",
      "195/195 [==============================] - 0s 452us/step - loss: 0.3292 - mean_squared_error: 0.3292\n",
      "Epoch 443/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3292 - mean_squared_error: 0.3292\n",
      "Epoch 444/500\n",
      "195/195 [==============================] - 0s 452us/step - loss: 0.3284 - mean_squared_error: 0.3284\n",
      "Epoch 445/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.4066 - mean_squared_error: 0.4066\n",
      "Epoch 446/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.4031 - mean_squared_error: 0.4031\n",
      "Epoch 447/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3572 - mean_squared_error: 0.3572\n",
      "Epoch 448/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.2975 - mean_squared_error: 0.2975\n",
      "Epoch 449/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3093 - mean_squared_error: 0.3093\n",
      "Epoch 450/500\n",
      "195/195 [==============================] - 0s 453us/step - loss: 0.3295 - mean_squared_error: 0.3295\n",
      "Epoch 451/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3505 - mean_squared_error: 0.3505\n",
      "Epoch 452/500\n",
      "195/195 [==============================] - 0s 450us/step - loss: 0.3513 - mean_squared_error: 0.3513\n",
      "Epoch 453/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.3622 - mean_squared_error: 0.3622\n",
      "Epoch 454/500\n",
      "195/195 [==============================] - 0s 466us/step - loss: 0.2838 - mean_squared_error: 0.2838\n",
      "Epoch 455/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.3768 - mean_squared_error: 0.3768\n",
      "Epoch 456/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.4016 - mean_squared_error: 0.4016\n",
      "Epoch 457/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.3680 - mean_squared_error: 0.3680\n",
      "Epoch 458/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3447 - mean_squared_error: 0.3447\n",
      "Epoch 459/500\n",
      "195/195 [==============================] - 0s 465us/step - loss: 0.3158 - mean_squared_error: 0.3158\n",
      "Epoch 460/500\n",
      "195/195 [==============================] - 0s 452us/step - loss: 0.3155 - mean_squared_error: 0.3155\n",
      "Epoch 461/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3403 - mean_squared_error: 0.3403\n",
      "Epoch 462/500\n",
      "195/195 [==============================] - 0s 450us/step - loss: 0.3297 - mean_squared_error: 0.3297\n",
      "Epoch 463/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3501 - mean_squared_error: 0.3501\n",
      "Epoch 464/500\n",
      "195/195 [==============================] - 0s 463us/step - loss: 0.3675 - mean_squared_error: 0.3675\n",
      "Epoch 465/500\n",
      "195/195 [==============================] - 0s 479us/step - loss: 0.3360 - mean_squared_error: 0.3360\n",
      "Epoch 466/500\n",
      "195/195 [==============================] - 0s 469us/step - loss: 0.3349 - mean_squared_error: 0.3349\n",
      "Epoch 467/500\n",
      "195/195 [==============================] - 0s 470us/step - loss: 0.3516 - mean_squared_error: 0.3516\n",
      "Epoch 468/500\n",
      "195/195 [==============================] - 0s 452us/step - loss: 0.4336 - mean_squared_error: 0.4336\n",
      "Epoch 469/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3346 - mean_squared_error: 0.3346\n",
      "Epoch 470/500\n",
      "195/195 [==============================] - 0s 462us/step - loss: 0.3547 - mean_squared_error: 0.3547\n",
      "Epoch 471/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.3240 - mean_squared_error: 0.3240\n",
      "Epoch 472/500\n",
      "195/195 [==============================] - 0s 462us/step - loss: 0.3419 - mean_squared_error: 0.3419\n",
      "Epoch 473/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.4088 - mean_squared_error: 0.4088\n",
      "Epoch 474/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3598 - mean_squared_error: 0.3598\n",
      "Epoch 475/500\n",
      "195/195 [==============================] - 0s 451us/step - loss: 0.3408 - mean_squared_error: 0.3408\n",
      "Epoch 476/500\n",
      "195/195 [==============================] - 0s 467us/step - loss: 0.4122 - mean_squared_error: 0.4122\n",
      "Epoch 477/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.3170 - mean_squared_error: 0.3170\n",
      "Epoch 478/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.3332 - mean_squared_error: 0.3332\n",
      "Epoch 479/500\n",
      "195/195 [==============================] - 0s 458us/step - loss: 0.3187 - mean_squared_error: 0.3187\n",
      "Epoch 480/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3352 - mean_squared_error: 0.3352\n",
      "Epoch 481/500\n",
      "195/195 [==============================] - 0s 483us/step - loss: 0.3414 - mean_squared_error: 0.3414\n",
      "Epoch 482/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3668 - mean_squared_error: 0.3668\n",
      "Epoch 483/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3180 - mean_squared_error: 0.3180\n",
      "Epoch 484/500\n",
      "195/195 [==============================] - 0s 454us/step - loss: 0.3353 - mean_squared_error: 0.3353\n",
      "Epoch 485/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.3151 - mean_squared_error: 0.3151\n",
      "Epoch 486/500\n",
      "195/195 [==============================] - 0s 466us/step - loss: 0.3042 - mean_squared_error: 0.3042\n",
      "Epoch 487/500\n",
      "195/195 [==============================] - 0s 466us/step - loss: 0.3577 - mean_squared_error: 0.3577\n",
      "Epoch 488/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3435 - mean_squared_error: 0.3435\n",
      "Epoch 489/500\n",
      "195/195 [==============================] - 0s 459us/step - loss: 0.4062 - mean_squared_error: 0.4062\n",
      "Epoch 490/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3778 - mean_squared_error: 0.3778\n",
      "Epoch 491/500\n",
      "195/195 [==============================] - 0s 457us/step - loss: 0.3448 - mean_squared_error: 0.3448\n",
      "Epoch 492/500\n",
      "195/195 [==============================] - 0s 466us/step - loss: 0.3219 - mean_squared_error: 0.3219\n",
      "Epoch 493/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3193 - mean_squared_error: 0.3193\n",
      "Epoch 494/500\n",
      "195/195 [==============================] - 0s 461us/step - loss: 0.3616 - mean_squared_error: 0.3616\n",
      "Epoch 495/500\n",
      "195/195 [==============================] - 0s 455us/step - loss: 0.3626 - mean_squared_error: 0.3626\n",
      "Epoch 496/500\n",
      "195/195 [==============================] - 0s 465us/step - loss: 0.3440 - mean_squared_error: 0.3440\n",
      "Epoch 497/500\n",
      "195/195 [==============================] - 0s 453us/step - loss: 0.3427 - mean_squared_error: 0.3427\n",
      "Epoch 498/500\n",
      "195/195 [==============================] - 0s 467us/step - loss: 0.3211 - mean_squared_error: 0.3211\n",
      "Epoch 499/500\n",
      "195/195 [==============================] - 0s 460us/step - loss: 0.3590 - mean_squared_error: 0.3590\n",
      "Epoch 500/500\n",
      "195/195 [==============================] - 0s 456us/step - loss: 0.3403 - mean_squared_error: 0.3403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x174887eb0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(rows):\n",
    "    result = model.predict(rows)\n",
    "    scaledRes = []\n",
    "    for i in result:\n",
    "        scaledRes += [yScaler.inverse_transform(i)]\n",
    "    return scaledRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(Xts, Yts, batch_size=128, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(X.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([950.,   1.,   4.,   2.,   0.,   1.,   1.,   5.,   1.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Squarefootage    950.0\n",
       "Type               1.0\n",
       "Style              4.0\n",
       "Bedrooms           2.0\n",
       "Dens               0.0\n",
       "Bathrooms          1.0\n",
       "Kitchens           1.0\n",
       "Rooms              5.0\n",
       "Parking Total      1.0\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Type': {'Co-op / Co-Ownership Apartment': 0, 'Condo Apartment': 1, 'Condo Townhouse': 2, 'Det Condo': 3, 'Detached': 4, 'Multiplex': 5, 'Other': 6, 'Semi-Detached': 7, 'Store W/Apt/Offc': 8, 'Townhouse': 9}, 'Style': {'1 1/2 Storey': 0, '2 1/2 Storey': 1, '2-Storey': 2, '3-Storey': 3, 'Apartment': 4, 'Bachelor/Studio': 5, 'Backsplit': 6, 'Bungalow': 7, 'Loft': 8, 'Sidesplit': 9, 'Stacked Townhouse': 10}}\n",
      "[[651170.3]]\n"
     ]
    }
   ],
   "source": [
    "# print(d)  \n",
    "# d = {1: {'name': 'John', 'age': '27', 'sex': 'Male'},\n",
    "#           2: {'name': 'Marie', 'age': '22', 'sex': 'Female'}}\n",
    "\n",
    "\n",
    "d = {'Type': {'Co-op / Co-Ownership Apartment': 0, 'Condo Apartment': 1, 'Condo Townhouse': 2, 'Det Condo': 3, 'Detached': 4, 'Multiplex': 5, 'Other': 6, 'Semi-Detached': 7, 'Store W/Apt/Offc': 8, 'Townhouse': 9}, 'Style': {'1 1/2 Storey': 0, '2 1/2 Storey': 1, '2-Storey': 2, '3-Storey': 3, 'Apartment': 4, 'Bachelor/Studio': 5, 'Backsplit': 6, 'Bungalow': 7, 'Loft': 8, 'Sidesplit': 9, 'Stacked Townhouse': 10}}\n",
    "\n",
    "print(d)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predict(sqft, property_type, style, bedrooms, dens, bathrooms, kitchens, rooms, parking):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    test_input = np.array([sqft, property_type, style, bedrooms, dens, bathrooms, kitchens, rooms, parking], dtype = 'object' )\n",
    "\n",
    "    test_input = np.array([950, 'Condo Apartment', 'Apartment', 2, 0, 1,1, 5, 1.0 ], dtype = 'object' )\n",
    "\n",
    "\n",
    "    test_input[1] = d['Type'][test_input[1]]\n",
    "    test_input[2] = d['Style'][test_input[2]]\n",
    "\n",
    "\n",
    "\n",
    "#     print(type(test_input))\n",
    "    test_input = test_input.reshape(1,9)\n",
    "#     print(test_input)\n",
    "\n",
    "    test_input = np.asarray(test_input).astype(np.float32)\n",
    "\n",
    "\n",
    "    load_model_from_file = tf.keras.models.load_model(\"./models/mvp_model\")\n",
    "\n",
    "    result = load_model_from_file.predict(test_input)\n",
    "#     print(result)\n",
    "    \n",
    "    \n",
    "    return yScaler.inverse_transform(result)\n",
    "\n",
    "# print(yScaler.inverse_transform(result))\n",
    "\n",
    "\n",
    "print(predict(950, 'Condo Apartment', 'Apartment', 2, 0, 1,1, 5, 1.0 ))\n",
    "\n",
    "\n",
    "# print(test_input)\n",
    "# print(test_input[1])\n",
    "# print(type(test_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[950.   1.   4.   2.   0.   1.   1.   5.   1.]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "x = np.array(X.iloc[0])\n",
    "\n",
    "x = x.reshape(1,9)\n",
    "\n",
    "print (x)\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/mvp_model/assets\n",
      "[[-0.401256]]\n",
      "[[651170.3]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.save(\"./models/mvp_model\")\n",
    "\n",
    "load_model_from_file = tf.keras.models.load_model(\"./models/mvp_model\")\n",
    "\n",
    "result = load_model_from_file.predict(x)\n",
    "print(result)\n",
    "print(yScaler.inverse_transform(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting and Training using a Hyperparameter Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from keras_tuner import Hyperband,RandomSearch\n",
    "import keras_tuner\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "callback = EarlyStopping(monitor='val_mean_absolute_error', patience=10, verbose=1)\n",
    "\n",
    "\n",
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=[X.shape[1]]))\n",
    "    for i in range(hp.Int(\"num_layers\", 2, 10)): #number of layers\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                units=hp.Int(\"units_\" + str(i), min_value=11, max_value=512, step=32), #number of units\n",
    "                activation=\"relu\",\n",
    "            )\n",
    "        )\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(hp.Choice(\"learning_rate\", [1e-2, 1e-3, 1e-4])),\n",
    "                loss=keras.losses.mean_absolute_error,\n",
    "              metrics=['mean_squared_error',r2,keras.losses.mean_absolute_error])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective=keras_tuner.Objective(\"val_r2\", direction=\"max\"),\n",
    "                     max_epochs=1000,\n",
    "                     executions_per_trial=3,\n",
    "                     overwrite=True,\n",
    "                     directory=\"my_dir\",\n",
    "                     project_name=\"KerasRegressor\",\n",
    "                    \n",
    ")\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 61 Complete [00h 00m 04s]\n",
      "val_r2: 0.22877928614616394\n",
      "\n",
      "Best val_r2 So Far: 0.4829423725605011\n",
      "Total elapsed time: 00h 04m 20s\n",
      "\n",
      "Search: Running Trial #62\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "num_layers        |8                 |2                 \n",
      "units_0           |331               |427               \n",
      "units_1           |43                |75                \n",
      "learning_rate     |0.0001            |0.01              \n",
      "units_2           |107               |491               \n",
      "units_3           |43                |203               \n",
      "units_4           |235               |171               \n",
      "units_5           |107               |235               \n",
      "units_6           |363               |299               \n",
      "units_7           |203               |299               \n",
      "units_8           |107               |459               \n",
      "units_9           |139               |11                \n",
      "tuner/epochs      |2                 |2                 \n",
      "tuner/initial_e...|0                 |0                 \n",
      "tuner/bracket     |6                 |6                 \n",
      "tuner/round       |0                 |0                 \n",
      "\n",
      "Epoch 1/2\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.5046 - mean_squared_error: 0.9784 - r2: -0.0359 - mean_absolute_error: 0.5046 - val_loss: 0.4238 - val_mean_squared_error: 0.7709 - val_r2: 0.2504 - val_mean_absolute_error: 0.4238\n",
      "Epoch 2/2\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.4148 - mean_squared_error: 0.7105 - r2: 0.3059 - mean_absolute_error: 0.4148 - val_loss: 0.3996 - val_mean_squared_error: 0.6612 - val_r2: 0.3341 - val_mean_absolute_error: 0.3996\n",
      "Epoch 1/2\n",
      " 92/140 [==================>...........] - ETA: 0s - loss: 0.5359 - mean_squared_error: 1.1532 - r2: -0.0775 - mean_absolute_error: 0.5359"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1f/gzrgws6s3bbfv99j9mptfmm40000gn/T/ipykernel_18141/3623185942.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/research/learning/keras_with_tensorflow_deepliz_freecode/VENV/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/learning/keras_with_tensorflow_deepliz_freecode/VENV/lib/python3.8/site-packages/keras_tuner/tuners/hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHyperband\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/learning/keras_with_tensorflow_deepliz_freecode/VENV/lib/python3.8/site-packages/keras_tuner/engine/multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_values\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"min\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/learning/keras_with_tensorflow_deepliz_freecode/VENV/lib/python3.8/site-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, fit_args, fit_kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \"\"\"\n\u001b[1;32m    146\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/learning/keras_with_tensorflow_deepliz_freecode/VENV/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/learning/keras_with_tensorflow_deepliz_freecode/VENV/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/learning/keras_with_tensorflow_deepliz_freecode/VENV/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/learning/keras_with_tensorflow_deepliz_freecode/VENV/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/learning/keras_with_tensorflow_deepliz_freecode/VENV/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/research/learning/keras_with_tensorflow_deepliz_freecode/VENV/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/learning/keras_with_tensorflow_deepliz_freecode/VENV/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(Xtr, Ytr, epochs=1000, validation_split=0.2,callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "# bestHparams=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "models_hyper = tuner.get_best_models(num_models=2)\n",
    "best_model = models_hyper[0]\n",
    "score = best_model.evaluate(Xts, Yts, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 0.3045 - mean_squared_error: 0.1758 - r2: -1.9423 - mean_absolute_error: 0.3045 - val_loss: 1.7181 - val_mean_squared_error: 5.0592 - val_r2: -38.6979 - val_mean_absolute_error: 1.7181\n",
      "Epoch 2/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.2012 - mean_squared_error: 0.0677 - r2: -0.0619 - mean_absolute_error: 0.2012 - val_loss: 1.6660 - val_mean_squared_error: 4.8625 - val_r2: -36.1137 - val_mean_absolute_error: 1.6660\n",
      "Epoch 3/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1746 - mean_squared_error: 0.0513 - r2: 0.1659 - mean_absolute_error: 0.1746 - val_loss: 1.5677 - val_mean_squared_error: 4.4545 - val_r2: -32.0261 - val_mean_absolute_error: 1.5677\n",
      "Epoch 4/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1678 - mean_squared_error: 0.0485 - r2: 0.2042 - mean_absolute_error: 0.1678 - val_loss: 1.6145 - val_mean_squared_error: 4.6135 - val_r2: -34.2416 - val_mean_absolute_error: 1.6145\n",
      "Epoch 5/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1675 - mean_squared_error: 0.0481 - r2: 0.2225 - mean_absolute_error: 0.1675 - val_loss: 1.5110 - val_mean_squared_error: 4.3253 - val_r2: -29.6994 - val_mean_absolute_error: 1.5110\n",
      "Epoch 6/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1585 - mean_squared_error: 0.0446 - r2: 0.2908 - mean_absolute_error: 0.1585 - val_loss: 1.4697 - val_mean_squared_error: 4.1648 - val_r2: -28.1249 - val_mean_absolute_error: 1.4697\n",
      "Epoch 7/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1552 - mean_squared_error: 0.0410 - r2: 0.3146 - mean_absolute_error: 0.1552 - val_loss: 1.4707 - val_mean_squared_error: 4.2045 - val_r2: -28.0657 - val_mean_absolute_error: 1.4707\n",
      "Epoch 8/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1559 - mean_squared_error: 0.0419 - r2: 0.3279 - mean_absolute_error: 0.1559 - val_loss: 1.4050 - val_mean_squared_error: 3.9831 - val_r2: -25.7179 - val_mean_absolute_error: 1.4050\n",
      "Epoch 9/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1499 - mean_squared_error: 0.0400 - r2: 0.3413 - mean_absolute_error: 0.1499 - val_loss: 1.4263 - val_mean_squared_error: 4.0136 - val_r2: -26.5868 - val_mean_absolute_error: 1.4263\n",
      "Epoch 10/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1477 - mean_squared_error: 0.0370 - r2: 0.3821 - mean_absolute_error: 0.1477 - val_loss: 1.4019 - val_mean_squared_error: 3.9522 - val_r2: -25.6327 - val_mean_absolute_error: 1.4019\n",
      "Epoch 11/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1445 - mean_squared_error: 0.0363 - r2: 0.4119 - mean_absolute_error: 0.1445 - val_loss: 1.4932 - val_mean_squared_error: 4.2772 - val_r2: -28.8730 - val_mean_absolute_error: 1.4932\n",
      "Epoch 12/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1468 - mean_squared_error: 0.0371 - r2: 0.4225 - mean_absolute_error: 0.1468 - val_loss: 1.4027 - val_mean_squared_error: 3.9508 - val_r2: -25.6513 - val_mean_absolute_error: 1.4027\n",
      "Epoch 13/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1485 - mean_squared_error: 0.0385 - r2: 0.3686 - mean_absolute_error: 0.1485 - val_loss: 1.4861 - val_mean_squared_error: 4.1971 - val_r2: -28.6569 - val_mean_absolute_error: 1.4861\n",
      "Epoch 14/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1413 - mean_squared_error: 0.0363 - r2: 0.4246 - mean_absolute_error: 0.1413 - val_loss: 1.4742 - val_mean_squared_error: 4.1948 - val_r2: -28.1899 - val_mean_absolute_error: 1.4742\n",
      "Epoch 15/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1356 - mean_squared_error: 0.0328 - r2: 0.4507 - mean_absolute_error: 0.1356 - val_loss: 1.3578 - val_mean_squared_error: 3.8119 - val_r2: -24.0425 - val_mean_absolute_error: 1.3578\n",
      "Epoch 16/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1480 - mean_squared_error: 0.0380 - r2: 0.4021 - mean_absolute_error: 0.1480 - val_loss: 1.4772 - val_mean_squared_error: 4.2229 - val_r2: -28.3482 - val_mean_absolute_error: 1.4772\n",
      "Epoch 17/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1351 - mean_squared_error: 0.0340 - r2: 0.4757 - mean_absolute_error: 0.1351 - val_loss: 1.4764 - val_mean_squared_error: 4.2229 - val_r2: -28.2999 - val_mean_absolute_error: 1.4764\n",
      "Epoch 18/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1332 - mean_squared_error: 0.0315 - r2: 0.4933 - mean_absolute_error: 0.1332 - val_loss: 1.4014 - val_mean_squared_error: 3.9317 - val_r2: -25.5567 - val_mean_absolute_error: 1.4014\n",
      "Epoch 19/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1289 - mean_squared_error: 0.0304 - r2: 0.5028 - mean_absolute_error: 0.1289 - val_loss: 1.4505 - val_mean_squared_error: 4.1487 - val_r2: -27.3446 - val_mean_absolute_error: 1.4505\n",
      "Epoch 20/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1321 - mean_squared_error: 0.0310 - r2: 0.4809 - mean_absolute_error: 0.1321 - val_loss: 1.4079 - val_mean_squared_error: 3.9375 - val_r2: -25.7652 - val_mean_absolute_error: 1.4079\n",
      "Epoch 21/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1308 - mean_squared_error: 0.0317 - r2: 0.4801 - mean_absolute_error: 0.1308 - val_loss: 1.4274 - val_mean_squared_error: 4.0485 - val_r2: -26.4977 - val_mean_absolute_error: 1.4274\n",
      "Epoch 22/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1262 - mean_squared_error: 0.0291 - r2: 0.5161 - mean_absolute_error: 0.1262 - val_loss: 1.4370 - val_mean_squared_error: 4.0251 - val_r2: -26.7514 - val_mean_absolute_error: 1.4370\n",
      "Epoch 23/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1324 - mean_squared_error: 0.0325 - r2: 0.4985 - mean_absolute_error: 0.1324 - val_loss: 1.4478 - val_mean_squared_error: 4.0776 - val_r2: -27.1564 - val_mean_absolute_error: 1.4478\n",
      "Epoch 24/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1301 - mean_squared_error: 0.0302 - r2: 0.5279 - mean_absolute_error: 0.1301 - val_loss: 1.4165 - val_mean_squared_error: 4.0163 - val_r2: -26.0873 - val_mean_absolute_error: 1.4165\n",
      "Epoch 25/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1254 - mean_squared_error: 0.0297 - r2: 0.5214 - mean_absolute_error: 0.1254 - val_loss: 1.3598 - val_mean_squared_error: 3.7548 - val_r2: -24.0084 - val_mean_absolute_error: 1.3598\n",
      "Epoch 26/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1303 - mean_squared_error: 0.0308 - r2: 0.5208 - mean_absolute_error: 0.1303 - val_loss: 1.4231 - val_mean_squared_error: 4.0184 - val_r2: -26.2811 - val_mean_absolute_error: 1.4231\n",
      "Epoch 27/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1248 - mean_squared_error: 0.0295 - r2: 0.5388 - mean_absolute_error: 0.1248 - val_loss: 1.3980 - val_mean_squared_error: 3.9900 - val_r2: -25.4886 - val_mean_absolute_error: 1.3980\n",
      "Epoch 28/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1186 - mean_squared_error: 0.0265 - r2: 0.5757 - mean_absolute_error: 0.1186 - val_loss: 1.3744 - val_mean_squared_error: 3.8832 - val_r2: -24.5731 - val_mean_absolute_error: 1.3744\n",
      "Epoch 29/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1207 - mean_squared_error: 0.0268 - r2: 0.5546 - mean_absolute_error: 0.1207 - val_loss: 1.4286 - val_mean_squared_error: 4.0370 - val_r2: -26.4621 - val_mean_absolute_error: 1.4286\n",
      "Epoch 30/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1292 - mean_squared_error: 0.0301 - r2: 0.5042 - mean_absolute_error: 0.1292 - val_loss: 1.3827 - val_mean_squared_error: 3.9197 - val_r2: -24.9156 - val_mean_absolute_error: 1.3827\n",
      "Epoch 31/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1172 - mean_squared_error: 0.0258 - r2: 0.5498 - mean_absolute_error: 0.1172 - val_loss: 1.4112 - val_mean_squared_error: 4.0089 - val_r2: -25.8598 - val_mean_absolute_error: 1.4112\n",
      "Epoch 32/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1191 - mean_squared_error: 0.0258 - r2: 0.5612 - mean_absolute_error: 0.1191 - val_loss: 1.3759 - val_mean_squared_error: 3.8452 - val_r2: -24.6329 - val_mean_absolute_error: 1.3759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1236 - mean_squared_error: 0.0278 - r2: 0.5546 - mean_absolute_error: 0.1236 - val_loss: 1.4232 - val_mean_squared_error: 4.0345 - val_r2: -26.2759 - val_mean_absolute_error: 1.4232\n",
      "Epoch 34/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1193 - mean_squared_error: 0.0264 - r2: 0.5765 - mean_absolute_error: 0.1193 - val_loss: 1.3972 - val_mean_squared_error: 3.9810 - val_r2: -25.3681 - val_mean_absolute_error: 1.3972\n",
      "Epoch 35/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1232 - mean_squared_error: 0.0280 - r2: 0.5391 - mean_absolute_error: 0.1232 - val_loss: 1.3369 - val_mean_squared_error: 3.6932 - val_r2: -23.2159 - val_mean_absolute_error: 1.3369\n",
      "Epoch 36/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1221 - mean_squared_error: 0.0278 - r2: 0.5382 - mean_absolute_error: 0.1221 - val_loss: 1.3691 - val_mean_squared_error: 3.8827 - val_r2: -24.4561 - val_mean_absolute_error: 1.3691\n",
      "Epoch 37/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1181 - mean_squared_error: 0.0263 - r2: 0.5742 - mean_absolute_error: 0.1181 - val_loss: 1.3961 - val_mean_squared_error: 3.9852 - val_r2: -25.3451 - val_mean_absolute_error: 1.3961\n",
      "Epoch 38/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1215 - mean_squared_error: 0.0275 - r2: 0.5597 - mean_absolute_error: 0.1215 - val_loss: 1.3940 - val_mean_squared_error: 3.8907 - val_r2: -25.1769 - val_mean_absolute_error: 1.3940\n",
      "Epoch 39/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1196 - mean_squared_error: 0.0270 - r2: 0.5712 - mean_absolute_error: 0.1196 - val_loss: 1.3993 - val_mean_squared_error: 3.9392 - val_r2: -25.3813 - val_mean_absolute_error: 1.3993\n",
      "Epoch 40/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1156 - mean_squared_error: 0.0247 - r2: 0.5845 - mean_absolute_error: 0.1156 - val_loss: 1.4555 - val_mean_squared_error: 4.0771 - val_r2: -27.5408 - val_mean_absolute_error: 1.4555\n",
      "Epoch 41/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1212 - mean_squared_error: 0.0275 - r2: 0.5466 - mean_absolute_error: 0.1212 - val_loss: 1.3532 - val_mean_squared_error: 3.8271 - val_r2: -23.8491 - val_mean_absolute_error: 1.3532\n",
      "Epoch 42/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1166 - mean_squared_error: 0.0253 - r2: 0.6002 - mean_absolute_error: 0.1166 - val_loss: 1.3757 - val_mean_squared_error: 3.9041 - val_r2: -24.6011 - val_mean_absolute_error: 1.3757\n",
      "Epoch 43/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1178 - mean_squared_error: 0.0255 - r2: 0.5913 - mean_absolute_error: 0.1178 - val_loss: 1.4830 - val_mean_squared_error: 4.4810 - val_r2: -28.9962 - val_mean_absolute_error: 1.4830\n",
      "Epoch 44/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1190 - mean_squared_error: 0.0268 - r2: 0.5526 - mean_absolute_error: 0.1190 - val_loss: 1.4131 - val_mean_squared_error: 4.0540 - val_r2: -25.9475 - val_mean_absolute_error: 1.4131\n",
      "Epoch 45/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1119 - mean_squared_error: 0.0237 - r2: 0.6075 - mean_absolute_error: 0.1119 - val_loss: 1.4297 - val_mean_squared_error: 4.1671 - val_r2: -26.6049 - val_mean_absolute_error: 1.4297\n",
      "Epoch 46/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1199 - mean_squared_error: 0.0263 - r2: 0.5708 - mean_absolute_error: 0.1199 - val_loss: 1.3859 - val_mean_squared_error: 3.9598 - val_r2: -25.0219 - val_mean_absolute_error: 1.3859\n",
      "Epoch 47/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1160 - mean_squared_error: 0.0249 - r2: 0.5705 - mean_absolute_error: 0.1160 - val_loss: 1.3431 - val_mean_squared_error: 3.7002 - val_r2: -23.4290 - val_mean_absolute_error: 1.3431\n",
      "Epoch 48/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1122 - mean_squared_error: 0.0234 - r2: 0.6193 - mean_absolute_error: 0.1122 - val_loss: 1.3766 - val_mean_squared_error: 3.9419 - val_r2: -24.6704 - val_mean_absolute_error: 1.3766\n",
      "Epoch 49/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1156 - mean_squared_error: 0.0254 - r2: 0.5811 - mean_absolute_error: 0.1156 - val_loss: 1.3240 - val_mean_squared_error: 3.6827 - val_r2: -22.8456 - val_mean_absolute_error: 1.3240\n",
      "Epoch 50/50\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.1154 - mean_squared_error: 0.0246 - r2: 0.6056 - mean_absolute_error: 0.1154 - val_loss: 1.3825 - val_mean_squared_error: 3.9146 - val_r2: -24.8167 - val_mean_absolute_error: 1.3825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c3fbdb20>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(bestHparams)\n",
    "model.fit(X, Y, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 1ms/step - loss: 0.3633 - mean_squared_error: 0.8014 - r2: -13.1551 - mean_absolute_error: 0.3633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36327672004699707,\n",
       " 0.8013868927955627,\n",
       " -13.155065536499023,\n",
       " 0.36327672004699707]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sqft, property_type, style, bedrooms, dens, bathrooms, kitchens, rooms, parking):\n",
    "    \n",
    "    \n",
    "    \n",
    "    test_input = np.array([sqft, property_type, style, bedrooms, dens, bathrooms, kitchens, rooms, parking], dtype = 'object' )\n",
    "\n",
    "    test_input = np.array([950, 'Condo Apartment', 'Apartment', 2, 0, 1,1, 5, 1.0 ], dtype = 'object' )\n",
    "\n",
    "\n",
    "    test_input[1] = d['Type'][test_input[1]]\n",
    "    test_input[2] = d['Style'][test_input[2]]\n",
    "\n",
    "\n",
    "\n",
    "    test_input = test_input.reshape(1,9)\n",
    "\n",
    "\n",
    "    test_input = np.asarray(test_input).astype(np.float32)\n",
    "\n",
    "\n",
    "    load_model_from_file = tf.keras.models.load_model(\"./models/mvp_model\")\n",
    "\n",
    "    result = load_model_from_file.predict(test_input)\n",
    "\n",
    "    \n",
    "    \n",
    "    return yScaler.inverse_transform(result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(predict(950, 'Condo Apartment', 'Apartment', 2, 0, 1,1, 5, 1.0 ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
